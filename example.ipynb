{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"city_name\": [\"Umeå\", \"Dresden\", \"Barcelona\"],\n",
    "    \"region\": [\"europe\", \"europe\", \"europe\"],\n",
    "    \"country\": [\"Sweden\", \"Germany\", \"Spain\"],\n",
    "})\n",
    "\n",
    "df = pd.read_csv(\"example/boeing_locations_with_regions.csv\")\n",
    "df = df.drop(columns=['train_station_lat','train_station_lon','train_station_name'])\n",
    "df.to_csv('100_city_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling origins across different cities and creating origin-destination pairs.\n",
    "\n",
    "## Prerequisites\n",
    "This repository builds on the python package OSMNx (v.2.0.1, https://osmnx.readthedocs.io/en/stable/). I recommend installing it via conda:\n",
    "```\n",
    "conda create -n ox -c conda-forge --strict-channel-priority osmnx\n",
    "```\n",
    "For sampling nodes based on city names two additional packages are required, namely geopy (v.2.3.1, https://geopy.readthedocs.io/en/stable/) and overpy (v.0.7, https://python-overpy.readthedocs.io/en/latest/)\n",
    "\n",
    "```\n",
    "pip install geopy\n",
    "pip install overpy\n",
    "```\n",
    "\n",
    "For visualizing routes and geometry on maps I use the folium package (v.0.19.4, https://python-visualization.github.io/folium/latest/) that is included in the OSMNx package, but for creating static images of these visualizations the Selenium package is required (v.4.28.0, https://www.selenium.dev/documentation/)\n",
    "\n",
    "```\n",
    "pip install selenium\n",
    "```\n",
    "\n",
    "## This example\n",
    "Cities are used as the basis to find random samples of intersections. The region and country names are nice to have, but they are not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The workflow for analyzing the routes begins with coordinate points used as origin locations.\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"city_name\": [\"Umeå\", \"Dresden\", \"Barcelona\"],\n",
    "    \"region\": [\"europe\", \"europe\", \"europe\"],\n",
    "    \"country\": [\"Sweden\", \"Germany\", \"Spain\"],\n",
    "})\n",
    "\n",
    "#df = pd.read_csv(\"example/boeing_locations_with_regions\")\n",
    "#df = df.drop(['train_station_lat','train_station_lon','train_station_name'])\n",
    "#df.to_csv('100_city_sample.csv')\n",
    "# To sample nodes from the cities we call use a method from sample_nodes.py\n",
    "import node_sampling\n",
    "\n",
    "df = node_sampling.get_random_nodes_for_all_cities(df,min_distance_km=1,sample_size=3)\n",
    "\n",
    "\n",
    "display(df)\n",
    "\n",
    "import os # for file operations\n",
    "\n",
    "if not os.path.exists(\"example\"):\n",
    "    os.makedirs(\"example\")\n",
    "df.to_csv(\"example/city_samples.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 41 (4254430607.py, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 42\u001b[0;36m\u001b[0m\n\u001b[0;31m    def process_row(row):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after 'for' statement on line 41\n"
     ]
    }
   ],
   "source": [
    "from origin_graph import origin_graph # for creating the origin graph object\n",
    "import os # for file operations\n",
    "import ast # for parsing string to tuple\n",
    "import pandas as pd # for reading the csv file\n",
    "import osmnx as ox # for plotting the graph\n",
    "import matplotlib.pyplot as plt # for plotting the graphs\n",
    "import multiprocessing\n",
    "\"\"\"\n",
    "The origin graph object requires the following parameters for instantiation:\n",
    "# Required parameters:\n",
    "- origin_point: The coordinate point of the city as a tuple (latitude, longitude)\n",
    "- distance_from_point: The distance from the origin point in meters to the sides of a bounding box.\n",
    "- city_name: The name of the city\n",
    "- network_type: The type of network to use. The default is 'drive'.\n",
    "\n",
    "# The following parameters are optional:\n",
    "- remove_parallel: A boolean to remove parallel edges in the graph. The default is False.\n",
    "- simplify: A boolean to simplify the graph. The default is False.\n",
    "- edge_attr_diff: The attribute to differentiate edges in the graph when simplifying the graph. The default is None.\n",
    "\n",
    "# Downloading a graph and weighing it can take some time. To speed up the process, you can load a graph from a file.\n",
    "- save_graphml: The path to save the graphml file.\n",
    "- load_graphml: The path to a graphml file to load.\n",
    "\"\"\"\n",
    "\n",
    "folder = \"example/local_origin_graphs\"\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "df = pd.read_csv(\"example/city_samples.csv\")\n",
    "\n",
    "df['graph_path'] = None\n",
    "\n",
    "def process_row(row, folder):\n",
    "    latlon_point = ast.literal_eval(row['node_latlon'])\n",
    "    og = origin_graph(origin_point=latlon_point, distance_from_point=2000,\n",
    "                      city_name=row[\"city_name\"], network_type='drive', remove_parallel=True, simplify=True)\n",
    "\n",
    "    graph_path = os.path.join(folder, f\"{row['city_name']}_{row['node_id']}.graphml\")\n",
    "    og.save_graph(graph_path)\n",
    "\n",
    "    # Plot the origin graph to see if something is obviously wrong\n",
    "    ox.plot_graph(og.graph, node_color='blue', node_size=10, edge_linewidth=1, edge_color='black', bgcolor='white',\n",
    "                   save=True, filepath=os.path.join(folder, f\"{row['city_name']}_{row['node_id']}.png\"),show=False)\n",
    "\n",
    "    return graph_path\n",
    "\n",
    "# Number of processes to use\n",
    "num_processes = multiprocessing.cpu_count()  # Adjust based on your system's capabilities\n",
    "\n",
    "# Use multiprocessing Pool for parallel processing\n",
    "with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "    # Use pool.apply_async for asynchronous processing\n",
    "    results = [pool.apply_async(process_row, args=(row, folder)) for index, row in df.iterrows()]\n",
    "\n",
    "    # Wait for all processes to complete and update the DataFrame\n",
    "    for index, result in enumerate(results):\n",
    "        try:\n",
    "            graph_path = result.get()\n",
    "            df.at[index, 'graph_path'] = graph_path\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {index}: {e}\")\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df.to_csv(\"example/city_samples.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next step is to add weights to the edges of the graph.\n",
    "\n",
    "from origin_graph import origin_graph # for creating the origin graph object\n",
    "import pandas as pd # for reading the csv file\n",
    "\n",
    "folder = \"example/local_origin_graphs\"\n",
    "df = pd.read_csv(\"example/city_samples.csv\")\n",
    "api_keys = pd.read_csv(\"api_keys.csv\")\n",
    "google_key = api_keys.loc[api_keys['service'] == 'Gmaps', 'key'].values[0]\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Adding weights to graph for {row['city_name']} node id {row['node_id']}\")\n",
    "    og = origin_graph.from_graphml(graphml_path=row['graph_path'])\n",
    "\n",
    "    # Adding the decision complexity weights may take some time.\n",
    "    og.add_simplest_paths_from_origin()\n",
    "    og.add_node_elevation(api_key=google_key)\n",
    "    og.add_weights('deviation_from_prototypical')\n",
    "    og.add_weights('node_degree')\n",
    "    og.add_weights('instruction_equivalent')\n",
    "\n",
    "    # We can print the edge weights to see which have been added.\n",
    "    \n",
    "    # Save the graph with the weights now added.\n",
    "    og.save_graph(row['graph_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from origin_graph import origin_graph # for creating the origin graph object\n",
    "import pandas as pd # for reading the csv file\n",
    "\n",
    "folder = \"example/local_origin_graphs\"\n",
    "df = pd.read_csv(\"example/city_samples.csv\")\n",
    "\n",
    "origins_od_pair_data = []\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Creating od-pairs for {row['city_name']} node id {row['node_id']}\")\n",
    "    og = origin_graph.from_graphml(graphml_path=row['graph_path'])\n",
    "\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - min_distance: The minimum distance in meters between the origin and destination points in great circle distance.\n",
    "    - max distance: The maximum distance in meters between the origin and destination points in great circle distance.\n",
    "    - sample_size: The number of origin-destination pairs to sample.\n",
    "\n",
    "    Return: a dataframe with each row corresponding to an origin-destination pair.\n",
    "    \"\"\"\n",
    "    og.create_od_pairs(min_radius=1000, max_radius=1500, sample_size=144)\n",
    "    od_pair_data = og.get_od_pair_data()\n",
    "    origins_od_pair_data.append(od_pair_data)\n",
    "\n",
    "origin_od_pairs = pd.concat(origins_od_pair_data)\n",
    "print(f\"Number of origin-destination pairs: {len(origin_od_pairs)} in the dataset.\")\n",
    "print(origin_od_pairs.head(n=2))\n",
    "origin_od_pairs.to_json(\"example/origin_od_pairs.json\",orient=\"records\",default_handler=str,indent=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import post_processing\n",
    "import pandas as pd\n",
    "od_pair_data = pd.read_json(\"example/origin_od_pairs.json\")\n",
    "\n",
    "od_pair_data = post_processing.label_length_outliers(od_pair_data)\n",
    "od_pair_data = post_processing.label_gridlike_groups(od_pair_data)\n",
    "\n",
    "# Before normalizing the complexity, we need to remove the length outliers.\n",
    "print(f\"od-pairs before removing length outliers {len(od_pair_data)}\")\n",
    "od_pair_data = od_pair_data[od_pair_data['length_outliers'] == False]\n",
    "print(f\"od-pairs after removing length outliers {len(od_pair_data)}\")\n",
    "od_pair_data = post_processing.normalize_complexity(od_pair_data)\n",
    "\n",
    "# The od-pair data contains lists and dictionaries that are not easily saved to a csv file, so we store it as a json file.\n",
    "# Still, there some columns that need to be serialized to strings such as shapely polygon objects.\n",
    "od_pair_data.to_json(\"example/origin_od_pairs.json\",orient=\"records\",default_handler=str,indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "od_pair_data = pd.read_json(\"example/origin_od_pairs.json\")\n",
    "\n",
    "\n",
    "od_pair_data['closest_strongest_lag'] = abs(od_pair_data['closest_strongest_lag'])\n",
    "\n",
    "od_pair_data = od_pair_data.sort_values(by=\"closest_strongest_lag\", ascending=True)\n",
    "\n",
    "\n",
    "city_counts = od_pair_data['city_name'].value_counts()\n",
    "city_counts.plot(kind='bar')\n",
    "plt.xlabel('City Name')\n",
    "plt.ylabel('Number of od-pairs')\n",
    "plt.title('Number of od-pairs in Each city')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osmnx201",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
