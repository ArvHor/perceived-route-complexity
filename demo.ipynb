{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The workflow for analyzing the routes begins with coordinate points used as origin locations.\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"city_name\": [\"Ume책\", \"Dresden\", \"Barcelona\"],\n",
    "    \"region\": [\"europe\", \"europe\", \"europe\"],\n",
    "    \"country\": [\"Sweden\", \"Germany\", \"Spain\"],\n",
    "})\n",
    "\n",
    "# To sample nodes from the cities we call use a method from sample_nodes.py\n",
    "import node_sampling\n",
    "\n",
    "df = node_sampling.get_random_nodes_for_all_cities(df,min_distance_km=3)\n",
    "\n",
    "\n",
    "display(df)\n",
    "\n",
    "import os # for file operations\n",
    "\n",
    "if not os.path.exists(\"example\"):\n",
    "    os.makedirs(\"example\")\n",
    "df.to_csv(\"example/city_samples.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from origin_graph import origin_graph # for creating the origin graph object\n",
    "import os # for file operations\n",
    "import ast # for parsing string to tuple\n",
    "import pandas as pd # for reading the csv file\n",
    "\"\"\"\n",
    "The origin graph object requires the following parameters for instantiation:\n",
    "# Required parameters:\n",
    "- origin_point: The coordinate point of the city as a tuple (latitude, longitude)\n",
    "- distance_from_point: The distance from the origin point in meters to the sides of a bounding box.\n",
    "- city_name: The name of the city\n",
    "- network_type: The type of network to use. The default is 'drive'.\n",
    "\n",
    "# The following parameters are optional:\n",
    "- remove_parallel: A boolean to remove parallel edges in the graph. The default is False.\n",
    "- simplify: A boolean to simplify the graph. The default is False.\n",
    "- edge_attr_diff: The attribute to differentiate edges in the graph when simplifying the graph. The default is None.\n",
    "\n",
    "# Downloading a graph and weighing it can take some time. To speed up the process, you can load a graph from a file.\n",
    "- save_graphml: The path to save the graphml file.\n",
    "- load_graphml: The path to a graphml file to load.\n",
    "\"\"\"\n",
    "\n",
    "folder = \"example/local_origin_graphs\"\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "df = pd.read_csv(\"example/city_samples.csv\")\n",
    "\n",
    "df['graph_path'] = None\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Creating origin graph for {row['city_name']} node id {row['node_id']}\")\n",
    "    latlon_point = ast.literal_eval(row['node_latlon'])\n",
    "    og = origin_graph(origin_point=latlon_point, distance_from_point=2000,\n",
    "                city_name=row[\"city_name\"], network_type='drive', remove_parallel=True, simplify=True)\n",
    "    \n",
    "    graph_path = os.path.join(folder, f\"{row['city_name']}_{row['node_id']}.graphml\")\n",
    "    print(f\"Saving graph to {graph_path}\")\n",
    "    og.save_graph(graph_path)\n",
    "\n",
    "    # Update the corresponding column in the dataframe\n",
    "    df.at[index, f'graph_path'] = graph_path\n",
    "\n",
    "df.to_csv(\"example/city_samples.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next step is to add weights to the edges of the graph.\n",
    "\n",
    "from origin_graph import origin_graph # for creating the origin graph object\n",
    "import os # for file operations\n",
    "import ast # for parsing string to tuple\n",
    "import pandas as pd # for reading the csv file\n",
    "\n",
    "folder = \"example/local_origin_graphs\"\n",
    "df = pd.read_csv(\"example/city_samples.csv\")\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Adding weights to graph for {row['city_name']} node id {row['node_id']}\")\n",
    "    og = origin_graph.from_graphml(graphml_path=row['graph_path'])\n",
    "\n",
    "    # Adding the decision complexity weights may take some time.\n",
    "    og.add_weights('decision_complexity')\n",
    "    og.add_weights('deviation_from_prototypical')\n",
    "    og.add_weights('node_degree')\n",
    "    og.add_weights('instruction_equivalent')\n",
    "\n",
    "    # We can print the edge weights to see which have been added.\n",
    "    print(og.edge_weights)\n",
    "\n",
    "    # Save the graph with weights\n",
    "    og.save_graph(row['graph_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding weights to graph for Ume책 node id 301742745\n",
      "Adding weights to graph for Ume책 node id 1058118293\n",
      "Adding weights to graph for Ume책 node id 1365315690\n",
      "Adding weights to graph for Dresden node id 18629648\n",
      "Adding weights to graph for Dresden node id 27044751\n",
      "Adding weights to graph for Dresden node id 24674195\n",
      "Adding weights to graph for Barcelona node id 3007755767\n",
      "Adding weights to graph for Barcelona node id 425768614\n",
      "Adding weights to graph for Barcelona node id 573420830\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All objects passed were None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     od_pairs \u001b[38;5;241m=\u001b[39m og\u001b[38;5;241m.\u001b[39mcreate_od_pairs(min_radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m950\u001b[39m, max_radius\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1050\u001b[39m, sample_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m144\u001b[39m)\n\u001b[1;32m     23\u001b[0m     origin_od_pairs\u001b[38;5;241m.\u001b[39mappend(od_pairs)\n\u001b[0;32m---> 25\u001b[0m origin_od_pairs \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43morigin_od_pairs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m origin_od_pairs\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample/origin_od_pairs.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/osmnx201/lib/python3.13/site-packages/pandas/core/reshape/concat.py:382\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/anaconda3/envs/osmnx201/lib/python3.13/site-packages/pandas/core/reshape/concat.py:445\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverify_integrity \u001b[38;5;241m=\u001b[39m verify_integrity\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;241m=\u001b[39m copy\n\u001b[0;32m--> 445\u001b[0m objs, keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[1;32m    448\u001b[0m ndims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ndims(objs)\n",
      "File \u001b[0;32m~/anaconda3/envs/osmnx201/lib/python3.13/site-packages/pandas/core/reshape/concat.py:541\u001b[0m, in \u001b[0;36m_Concatenator._clean_keys_and_objs\u001b[0;34m(self, objs, keys)\u001b[0m\n\u001b[1;32m    538\u001b[0m         keys \u001b[38;5;241m=\u001b[39m Index(clean_keys, name\u001b[38;5;241m=\u001b[39mname, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(keys, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 541\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll objects passed were None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m objs_list, keys\n",
      "\u001b[0;31mValueError\u001b[0m: All objects passed were None"
     ]
    }
   ],
   "source": [
    "from origin_graph import origin_graph # for creating the origin graph object\n",
    "import os # for file operations\n",
    "import ast # for parsing string to tuple\n",
    "import pandas as pd # for reading the csv file\n",
    "\n",
    "folder = \"example/local_origin_graphs\"\n",
    "df = pd.read_csv(\"example/city_samples.csv\")\n",
    "\n",
    "origin_od_pairs = []\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Adding weights to graph for {row['city_name']} node id {row['node_id']}\")\n",
    "    og = origin_graph.from_graphml(graphml_path=row['graph_path'])\n",
    "\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - min_distance: The minimum distance in meters between the origin and destination points in great circle distance.\n",
    "    - max distance: The maximum distance in meters between the origin and destination points in great circle distance.\n",
    "    - sample_size: The number of origin-destination pairs to sample.\n",
    "\n",
    "    Return: a dataframe with each row corresponding to an origin-destination pair.\n",
    "    \"\"\"\n",
    "    od_pairs = og.create_od_pairs(min_radius=950, max_radius=1050, sample_size=144)\n",
    "    origin_od_pairs.append(od_pairs)\n",
    "\n",
    "origin_od_pairs = pd.concat(origin_od_pairs)\n",
    "origin_od_pairs.to_csv(\"example/origin_od_pairs.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osmnx201",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
